# Kaggle-Reading-Group


### XLNet | Kaggle

This week we're starting a new paper in the Kaggle reading group: XLNet: Generalized Autoregressive Pretraining for Language Understanding (Yang et al, unpublished). 

You can read the paper here: https://arxiv.org/abs/1906.08237 


### Universal Sentence Encoder (Part 2) | Kaggle

Join Kaggle Data Scientist Rachael as she reads through paper "Universal Sentence Encoder" by Cer et al. (Unpublished.) 

Link to paper: https://arxiv.org/pdf/1803.11175.pdf


### Generating Long Sequences with Sparse Transformers (Part 3)| Kaggle

Join Kaggle Data Scientist Rachael as she reads through an NLP paper! Today's paper is "Generating Long Sequences with Sparse Transformers" (Child et al, unpublished). 

You can find a copy here: https://arxiv.org/pdf/1904.10509.pdf


### Multi-Task DNNs for Natural Language Understanding (Part 3) | Kaggle

Join Kaggle Data Scientist Rachael as she reads through an NLP paper! Today's paper is "Multi-Task Deep Neural Networks for Natural Language Understanding " (Liu et al, unpublished). 

You can find a copy here: https://arxiv.org/pdf/1901.11504.pdf


### Dissecting contextual word embeddings (Part 4) | Kaggle

Join Kaggle Data Scientist Rachael as she reads through an NLP paper! Today's paper is "Dissecting contextual word embeddings: Architecture and representation" (Peters et al, 2018). 

You can find a copy here: https://aclweb.org/anthology/D18-1179

### Probing the Need for Visual Context in Multimodal Machine Translation| Kaggle

Join us for a special Kaggle Days edition of the Kaggle reading group! We'll be reading the recently-annouced best short paper from NAACL 2019; "Probing the Need for Visual Context in Multimodal Machine Translation". 

You can find a copy here: https://arxiv.org/pdf/1903.08678.pdf

### Language Models are Unsupervised Multitask Learners (GPT-2, Part 3) | Kaggle

Join Kaggle Data Scientist Rachael as she reads through an NLP paper! Today's paper is "Language Models are Unsupervised Multitask Learners" (Radford et al, unpublished). 


You can find a copy here: https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf



### Bidirectional Encoder Representations from Transformers (aka BERT) (Part 4)

Join Kaggle Data Scientist Rachael as she reads through an NLP paper! Today's paper is "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding" (Devlin et al, unpublished). 

You can find a copy here: https://arxiv.org/pdf/1810.04805.pdf

### Attention is all You Need (Pt. 3) | Kaggle

Join Kaggle Data Scientist Rachael as she reads through an NLP paper! Today's paper is "Attention is All You Need" (Vaswani et al 2017). 

You can find a copy here: https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf


